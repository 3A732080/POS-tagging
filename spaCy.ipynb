{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 詞性標注練習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝\n",
    "# pip install spacy\n",
    "# python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List         NOUN       compound\n",
      "suppliers    NOUN       ROOT\n",
      "who          PRON       nsubj\n",
      "supply       VERB       relcl\n",
      "red          ADJ        amod\n",
      "parts        NOUN       dobj\n",
      "?            PUNCT      punct\n"
     ]
    }
   ],
   "source": [
    "# 載入英文模型\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# 要分析的句子\n",
    "sentence = \"List suppliers who supply red parts?\"\n",
    "\n",
    "# 使用 spaCy 處理句子\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# 輸出每個詞彙的文本、通用詞性和詳細詞性\n",
    "for token in doc:\n",
    "    print(f\"{token.text:12} {token.pos_:10} {token.dep_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List         VERB       ROOT\n",
      "the          DET        det\n",
      "students     NOUN       dobj\n",
      "who          PRON       nsubj\n",
      "take         VERB       relcl\n",
      "the          DET        det\n",
      "course       NOUN       dobj\n",
      "taught       VERB       acl\n",
      "by           ADP        agent\n",
      "Frank        PROPN      pobj\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "sen = \"List the students who take the course taught by Frank\"\n",
    "doc = nlp(sen)\n",
    "for token in doc:\n",
    "    print(f\"{token.text:12} {token.pos_:10} {token.dep_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suppliers\n"
     ]
    }
   ],
   "source": [
    "response_data = {\n",
    "    'data': {\n",
    "        'Get': {\n",
    "            'Table': [\n",
    "                {\n",
    "                    '_additional': {'distance': 0.29302722, 'id': 'eaf6f825-3992-4dc4-9888-e64ddcf0ab3f'},\n",
    "                    'name': 'Suppliers',\n",
    "                    'ref': {'tag': ['subject', 'object', 'verb']}\n",
    "                },\n",
    "                {\n",
    "                    '_additional': {'distance': 0.6119833, 'id': '7538c959-7790-49a8-b52e-ecdc95773eb0'},\n",
    "                    'name': 'Shipments',\n",
    "                    'ref': {'tag': ['subject', 'object', 'verb']}\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "name = response_data['data']['Get']['Table'][0]['name']\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回傳為空陣列(Value)\n",
      "回傳為空陣列(Table)\n",
      "回傳為空陣列(Column)\n",
      "回傳不為空陣列(Table)\n"
     ]
    }
   ],
   "source": [
    "# 檢查回傳是否為空陣列\n",
    "def is_empty_result(response, key_name):\n",
    "    if 'data' in response and 'Get' in response['data']:\n",
    "        get_data = response['data']['Get']\n",
    "        if key_name in get_data:\n",
    "            return isinstance(get_data[key_name], list) and len(get_data[key_name]) == 0\n",
    "    return False\n",
    "\n",
    "# 使用例子\n",
    "response_empty_array_value = {'data': {'Get': {'Value': []}}}\n",
    "response_empty_array_table = {'data': {'Get': {'Table': []}}}\n",
    "response_empty_array_column = {'data': {'Get': {'Column': []}}}\n",
    "response_with_data = {'data': {'Get': {'Table': [{'_additional': {'distance': 0.32905298, 'id': 'e58b7533-168d-4c8c-bf04-f387fd9c5053'}, 'name': 'Parts', 'ref': {'tag': ['subject', 'object', 'verb']}}]}}}\n",
    "\n",
    "if is_empty_result(response_empty_array_value, 'Value'):\n",
    "    print(\"回傳為空陣列(Value)\")\n",
    "else:\n",
    "    print(\"回傳不為空陣列(Value)\")\n",
    "\n",
    "if is_empty_result(response_empty_array_table, 'Table'):\n",
    "    print(\"回傳為空陣列(Table)\")\n",
    "else:\n",
    "    print(\"回傳不為空陣列(Table)\")\n",
    "\n",
    "if is_empty_result(response_empty_array_column, 'Column'):\n",
    "    print(\"回傳為空陣列(Column)\")\n",
    "else:\n",
    "    print(\"回傳不為空陣列(Column)\")\n",
    "\n",
    "if is_empty_result(response_with_data, 'Table'):\n",
    "    print(\"回傳為空陣列(Table)\")\n",
    "else:\n",
    "    print(\"回傳不為空陣列(Table)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List         compound   suppliers    NOUN      \n",
      "suppliers    ROOT       suppliers    NOUN      \n",
      "who          nsubj      supply       VERB      \n",
      "supply       relcl      suppliers    NOUN      \n",
      "all          det        parts        NOUN      \n",
      "red          amod       parts        NOUN      \n",
      "parts        dobj       supply       VERB      \n",
      "or           cc         supply       VERB      \n",
      "are          auxpass    located      VERB      \n",
      "not          neg        located      VERB      \n",
      "located      conj       supply       VERB      \n",
      "in           prep       located      VERB      \n",
      "Paris        pobj       in           ADP       \n",
      ".            punct      suppliers    NOUN      \n",
      "\n",
      "相对子句:\n",
      "who supply all red parts or are not located in Paris\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 示例句子\n",
    "text = \"List suppliers who supply all red parts or are not located in Paris.\"\n",
    "\n",
    "# 使用 spaCy 处理文本\n",
    "doc = nlp(text)\n",
    "\n",
    "# 打印句法依存关系\n",
    "for token in doc:\n",
    "    print(f\"{token.text:{12}} {token.dep_:{10}} {token.head.text:{12}} {token.head.pos_:{10}}\")\n",
    "\n",
    "# 识别相对子句\n",
    "relative_clauses = []\n",
    "for token in doc:\n",
    "    if token.dep_ == \"relcl\":\n",
    "        clause = \" \".join([tok.text for tok in token.subtree])\n",
    "        relative_clauses.append(clause)\n",
    "\n",
    "print(\"\\n相对子句:\")\n",
    "for clause in relative_clauses:\n",
    "    print(clause)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "条件:\n",
      "who supply all red parts\n",
      "are not located in Paris\n"
     ]
    }
   ],
   "source": [
    "# 示例句子\n",
    "text = \"List suppliers who supply all red parts or are not located in Paris.\"\n",
    "\n",
    "# 使用 spaCy 处理文本\n",
    "doc = nlp(text)\n",
    "\n",
    "# 初始化条件列表\n",
    "conditions = []\n",
    "\n",
    "# 遍历句子中的 token\n",
    "for token in doc:\n",
    "    # 查找相对子句的起始点（通常是由 \"who\" 引导）\n",
    "    if token.dep_ == \"relcl\":\n",
    "        # 从相对子句的起始点收集子树中的 token 文本\n",
    "        clause = \" \".join([tok.text for tok in token.subtree])\n",
    "        conditions.append(clause)\n",
    "\n",
    "# 分割条件的函数\n",
    "def split_conditions(conditions):\n",
    "    split_conditions = []\n",
    "    for condition in conditions:\n",
    "        # 处理 \"and\" 和 \"or\" 连接的情况\n",
    "        if ' or ' in condition:\n",
    "            parts = condition.split(' or ')\n",
    "            split_conditions.extend(parts)\n",
    "        if ' and ' in condition:\n",
    "            parts = condition.split(' and ')\n",
    "            split_conditions.extend(parts)\n",
    "    return split_conditions\n",
    "\n",
    "# 尝试进一步分割条件\n",
    "split_conditions = split_conditions(conditions)\n",
    "\n",
    "print(\"条件:\")\n",
    "for condition in split_conditions:\n",
    "    print(condition)\n",
    "\n",
    "# 待解決：找出條件是修飾說誰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到的条件：\n",
      "in Paris\n"
     ]
    }
   ],
   "source": [
    "# 示例句子\n",
    "text = \"List suppliers located in Paris.\"\n",
    "\n",
    "# 使用 spaCy 处理文本\n",
    "doc = nlp(text)\n",
    "\n",
    "# 初始化条件列表\n",
    "conditions = []\n",
    "\n",
    "# 遍历句子中的 token\n",
    "for token in doc:\n",
    "    # 检查 token 是否为介词\n",
    "    if token.pos_ == \"ADP\":  # ADP 代表介词\n",
    "        # 收集介词短语中的 token 文本\n",
    "        prepositional_phrase = \" \".join([tok.text for tok in token.subtree])\n",
    "        conditions.append(prepositional_phrase)\n",
    "\n",
    "# 根据是否找到条件来打印相应的信息\n",
    "if conditions:\n",
    "    print(\"找到的条件：\")\n",
    "    for condition in conditions:\n",
    "        print(condition)\n",
    "else:\n",
    "    print(\"未找到明确的条件。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子主體註記：\n",
      "否定：False，包含 'all'：False\n",
      "\n",
      "子句的條件、修飾詞彙及註記：\n",
      "條件：'who supply red parts'，修飾的詞彙：suppliers，否定：False，包含 'all'：False\n"
     ]
    }
   ],
   "source": [
    "# 功能全都正常，待解決 isnt 的問題(似乎只有子句有問題)\n",
    "\n",
    "def process_and_annotate_sentence(text):\n",
    "    doc = nlp(text)\n",
    "    # Flags for main clause\n",
    "    main_clause_negation = False\n",
    "    main_clause_all = False\n",
    "    conditions = []\n",
    "    has_subclause = False\n",
    "\n",
    "    # Detect 'all' in the main clause by checking tokens outside any subclause\n",
    "    main_clause_tokens = [token.text.lower() for token in doc if not list(token.ancestors) or all(ancestor.dep_ != 'relcl' for ancestor in token.ancestors)]\n",
    "    if \"all\" in main_clause_tokens:\n",
    "        main_clause_all = True\n",
    "\n",
    "    # Process each token in the document\n",
    "    for token in doc:\n",
    "        # Check for negation in the main clause\n",
    "        if token.dep_ == \"neg\" and not any(ancestor.dep_ == \"relcl\" for ancestor in token.ancestors):\n",
    "            main_clause_negation = True\n",
    "\n",
    "        # Process relative clauses ('relcl' dependency)\n",
    "        if token.dep_ == \"relcl\":\n",
    "            has_subclause = True\n",
    "            clause = \" \".join([tok.text for tok in token.subtree])\n",
    "            modified_noun = token.head.text\n",
    "            \n",
    "            # Directly determine negation and \"all\" within the subclause\n",
    "            conditions.append((clause, modified_noun))\n",
    "\n",
    "    split_conditions = split_and_annotate_conditions(conditions)\n",
    "\n",
    "    # Print annotations\n",
    "    print_annotations(main_clause_negation, main_clause_all, split_conditions, has_subclause)\n",
    "\n",
    "def split_and_annotate_conditions(conditions):\n",
    "    split_conditions = []\n",
    "    for condition, modified_noun in conditions:\n",
    "        if ' or ' in condition:\n",
    "            parts = condition.split(' or ')\n",
    "            split_conditions.extend([(part.strip(), modified_noun) for part in parts])\n",
    "        elif ' and ' in condition:\n",
    "            parts = condition.split(' and ')\n",
    "            split_conditions.extend([(part.strip(), modified_noun) for part in parts])\n",
    "        else:\n",
    "            split_conditions.append((condition, modified_noun))\n",
    "    \n",
    "    return identify_negation_and_all(split_conditions)\n",
    "\n",
    "def identify_negation_and_all(split_conditions):\n",
    "    annotated_conditions = []\n",
    "    for condition, modified_noun in split_conditions:\n",
    "        negation = \"not\" in condition.lower()\n",
    "        all_quantifier = \"all\" in condition.lower()\n",
    "        annotation = {\n",
    "            \"condition\": condition,\n",
    "            \"modified_noun\": modified_noun,\n",
    "            \"negation\": negation,\n",
    "            \"all\": all_quantifier\n",
    "        }\n",
    "        annotated_conditions.append(annotation)\n",
    "    return annotated_conditions\n",
    "\n",
    "def print_annotations(main_clause_negation, main_clause_all, annotated_conditions, has_subclause):\n",
    "    print(f\"句子主體註記：\\n否定：{main_clause_negation}，包含 'all'：{main_clause_all}\")\n",
    "    if has_subclause:\n",
    "        print(\"\\n子句的條件、修飾詞彙及註記：\")\n",
    "        for annotation in annotated_conditions:\n",
    "            print(f\"條件：'{annotation['condition']}'，修飾的詞彙：{annotation['modified_noun']}，否定：{annotation['negation']}，包含 'all'：{annotation['all']}\")\n",
    "    else:\n",
    "        print(\"\\n子句是否存在：False\")\n",
    "\n",
    "# Example sentence\n",
    "text = \"List suppliers who supply red parts.\"\n",
    "process_and_annotate_sentence(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
